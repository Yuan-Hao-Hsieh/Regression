{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 波士頓房價預測\n",
    "- 計算linear regression training data & testing data 的 MSE&RMSE。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interception :  21.993333333333336\n",
      "Coeficient :  [-1.09299765  0.97431655  0.17589472  0.51612013 -1.98125482  2.99665496\n",
      " -0.61026711 -2.94464351  2.06984891 -2.07443678 -2.0915885   0.89475279\n",
      " -2.94995322]\n",
      "Mean Squared Error in training data: 16.69221271088402\n",
      "Mean Squared Error in testing data: 31.454047664950842\n",
      "Root Mean Squared Error in training data: 4.085610445317079\n",
      "Root Mean Squared Error in testing data: 5.608390826694484\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 導入數據集\n",
    "boston = pd.read_csv('HousingData.csv')\n",
    "# 处理缺失值（这里假设我们选择删除含有缺失值的行）\n",
    "boston = boston.dropna()\n",
    "boston = pd.get_dummies(boston)\n",
    "# 分割數據集為訓練資料跟測試資料\n",
    "X = boston.drop('MEDV', axis=1)  # 特征变量\n",
    "y = boston['MEDV']  # 目标变量（房價）\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True, \n",
    ")\n",
    "\n",
    "#標準化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#多元線性回歸模型\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "#印出各項參數及截距項\n",
    "w_0 = model.intercept_\n",
    "w_1 = model.coef_\n",
    "print('Interception : ', w_0)\n",
    "print('Coeficient : ', w_1)\n",
    "# 用mse及rmse評估模型效能\n",
    "mse_train = mean_squared_error(y_train, model.predict(X_train_scaled))\n",
    "mse_test = mean_squared_error(y_test, model.predict(X_test_scaled))\n",
    "rmse_train = root_mean_squared_error(y_train, model.predict(X_train_scaled))\n",
    "rmse_test = root_mean_squared_error(y_test, model.predict(X_test_scaled))\n",
    "print(f'Mean Squared Error in training data: {mse_train}')\n",
    "print(f'Mean Squared Error in testing data: {mse_test}')\n",
    "print(f'Root Mean Squared Error in training data: {rmse_train}')\n",
    "print(f'Root Mean Squared Error in testing data: {rmse_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用Cross validation 找出最好的 $\\lambda$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha : 6.135907273413176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "\n",
    "alphas = np.logspace(-6, 6, 100)\n",
    "ridge_model = RidgeCV(alphas=alphas, store_cv_values=True)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "best_alpha = ridge_model.alpha_\n",
    "print(f\"best alpha : {best_alpha}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 計算ridge regression training data & testing data 的 MSE&RMSE($\\lambda$ = best_alpha)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interception :  21.993333333333336\n",
      "Coeficient :  [-1.02098346  0.86101439 -0.03053942  0.54594324 -1.73092966  3.02100604\n",
      " -0.59223441 -2.66643297  1.56560399 -1.59366338 -2.03451539  0.88146107\n",
      " -2.88941807]\n",
      "Mean Squared Error in training data: 16.75297019676133\n",
      "Mean Squared Error in testing data: 31.940995362225927\n",
      "Root Mean Squared Error in training data: 4.093039237139235\n",
      "Root Mean Squared Error in testing data: 5.651636520710256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# ridge regression 模型\n",
    "Ridge_model = Ridge(alpha=best_alpha)\n",
    "Ridge_model.fit(X_train_scaled, y_train)\n",
    "w_0 = Ridge_model.intercept_\n",
    "w_1 =Ridge_model.coef_\n",
    "print('Interception : ', w_0)\n",
    "print('Coeficient : ', w_1)\n",
    "# 用mse及rmse評估模型效能\n",
    "mse_train = mean_squared_error(y_train, Ridge_model.predict(X_train_scaled))\n",
    "mse_test = mean_squared_error(y_test, Ridge_model.predict(X_test_scaled))\n",
    "rmse_train = root_mean_squared_error(y_train, Ridge_model.predict(X_train_scaled))\n",
    "rmse_test = root_mean_squared_error(y_test, Ridge_model.predict(X_test_scaled))\n",
    "print(f'Mean Squared Error in training data: {mse_train}')\n",
    "print(f'Mean Squared Error in testing data: {mse_test}')\n",
    "print(f'Root Mean Squared Error in training data: {rmse_train}')\n",
    "print(f'Root Mean Squared Error in testing data: {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of linear regression: 31.454047664950842\n",
      "The MSE of ridge regression: 31.940995362225927\n",
      "The score of linear regression (R^2): 0.6270849941673194\n",
      "The score of ridge regression  (R^2): 0.6213118070308387\n",
      "best alpha: 6.135907273413176\n",
      "The MSE of linear regression is lower than ridge regression。\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 5. 訓練回歸模型\n",
    "ridge_model = Ridge(alpha=best_alpha) \n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. 预测\n",
    "y_pred_linear = linear_model.predict(X_test_scaled)\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# 7. 計算均方誤差\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "score_linear = r2_score(y_test, y_pred_linear)\n",
    "score_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "# 8. 输出结果\n",
    "print(f\"The MSE of linear regression: {mse_linear}\")\n",
    "print(f\"The MSE of ridge regression: {mse_ridge}\")\n",
    "print(f\"The score of linear regression (R^2): {score_linear}\")\n",
    "print(f\"The score of ridge regression  (R^2): {score_ridge}\")\n",
    "print(f\"best alpha: {best_alpha}\")\n",
    "# 9. 對比模型\n",
    "if mse_linear < mse_ridge:\n",
    "    print(\"The MSE of linear regression is lower than ridge regression。\")\n",
    "else:\n",
    "    print(\"The MSE of ridge regression is lower than linear regression。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在高次方做CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在一次回歸當中看不出什麼區別，將資料運用到高次方回歸當中如下所示:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "alphas = np.logspace(-6, 6, 100)\n",
    "ridge_model = RidgeCV(alphas=alphas, store_cv_values=True)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "best_alpha = ridge_model.alpha_\n",
    "print(f\"best alpha : {best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error in training data: 7.794822005268475e-26\n",
      "Mean Squared Error in testing data: 441.6247125109677\n",
      "Root Mean Squared Error in training data: 2.7919208450936564e-13\n",
      "Root Mean Squared Error in testing data: 21.014868843534753\n"
     ]
    }
   ],
   "source": [
    "## 導入多項式套件，建構多項式迴歸模型所需的套件\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "regressor = make_pipeline(PolynomialFeatures(4), LinearRegression())\n",
    "regressor.fit(X_train_scaled, y_train)\n",
    "mse_train = mean_squared_error(y_train, regressor.predict(X_train_scaled))\n",
    "mse_test = mean_squared_error(y_test, regressor.predict(X_test_scaled))\n",
    "rmse_train = root_mean_squared_error(y_train, regressor.predict(X_train_scaled))\n",
    "rmse_test = root_mean_squared_error(y_test, regressor.predict(X_test_scaled))\n",
    "print(f'Mean Squared Error in training data: {mse_train}')\n",
    "print(f'Mean Squared Error in testing data: {mse_test}')\n",
    "print(f'Root Mean Squared Error in training data: {rmse_train}')\n",
    "print(f'Root Mean Squared Error in testing data: {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error in training data: 0.49615676149933885\n",
      "Mean Squared Error in testing data: 42.95440057130164\n",
      "Root Mean Squared Error in training data: 0.7043839588600374\n",
      "Root Mean Squared Error in testing data: 6.553960678193121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# ridge regression 模型\n",
    "ridge_regressor = make_pipeline(PolynomialFeatures(4), Ridge(alpha=best_alpha))\n",
    "ridge_regressor.fit(X_train_scaled, y_train)\n",
    "# 用mse及rmse評估模型效能\n",
    "mse_train = mean_squared_error(y_train, ridge_regressor.predict(X_train_scaled))\n",
    "mse_test = mean_squared_error(y_test, ridge_regressor.predict(X_test_scaled))\n",
    "rmse_train = root_mean_squared_error(y_train, ridge_regressor.predict(X_train_scaled))\n",
    "rmse_test = root_mean_squared_error(y_test, ridge_regressor.predict(X_test_scaled))\n",
    "print(f'Mean Squared Error in training data: {mse_train}')\n",
    "print(f'Mean Squared Error in testing data: {mse_test}')\n",
    "print(f'Root Mean Squared Error in training data: {rmse_train}')\n",
    "print(f'Root Mean Squared Error in testing data: {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of linear regression: 441.6247125109677\n",
      "The MSE of ridge regression: 42.95440057130164\n",
      "The score of linear regression (R^2): -4.235843856922596\n",
      "The score of ridge regression  (R^2): 0.4907383396180378\n",
      "best alpha: 6.135907273413176\n",
      "The MSE of ridge regression is lower than linear regression。\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "regressor = make_pipeline(PolynomialFeatures(4), LinearRegression())\n",
    "regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 訓練回歸模型\n",
    "ridge_regressor = make_pipeline(PolynomialFeatures(4), Ridge(alpha=best_alpha))\n",
    "ridge_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. 预测\n",
    "y_pred_linear = regressor.predict(X_test_scaled)\n",
    "y_pred_ridge = ridge_regressor.predict(X_test_scaled)\n",
    "\n",
    "# 7. 計算均方誤差\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "score_linear = r2_score(y_test, y_pred_linear)\n",
    "score_ridge = r2_score(y_test, y_pred_ridge)\n",
    "# 8. 输出结果\n",
    "print(f\"The MSE of linear regression: {mse_linear}\")\n",
    "print(f\"The MSE of ridge regression: {mse_ridge}\")\n",
    "print(f\"The score of linear regression (R^2): {score_linear}\")\n",
    "print(f\"The score of ridge regression  (R^2): {score_ridge}\")\n",
    "print(f\"best alpha: {best_alpha}\")\n",
    "# 9. 對比模型\n",
    "if mse_linear < mse_ridge:\n",
    "    print(\"The MSE of linear regression is lower than ridge regression。\")\n",
    "else:\n",
    "    print(\"The MSE of ridge regression is lower than linear regression。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 當多項式回歸次方項越高就越能發現ridge regression 對測試資料的mse下降越多。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_evnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
