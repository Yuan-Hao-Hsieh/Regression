{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **作業四、 SRCNN在影像辨識與生成的練習**\n",
    "\n",
    "### 姓名：謝元皓\n",
    "### 學號：410978002\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料介紹\n",
    "- 91張花朵之清晰圖像及來自Set5、Set14資料集的19張清晰圖像。\n",
    "\n",
    "- 32*32的兩萬張小圖。\n",
    "\n",
    "- 製作兩萬張小圖的殘差圖，即原小圖減掉模糊小圖的圖片。\n",
    "### 作品目標\n",
    "這份作品基於 SRCNN (Super-Resolution Convolutional Neural Network) 模型，進行高解析度影像生成的訓練和測試。與上課下載的程式碼不同之處包括：\n",
    "\n",
    "1. 額外的訓練次數：在原本的預訓練基礎上進行了額外的兩次訓練。\n",
    "2. PSNR 計算和展示：在每個訓練週期後計算並展示 Train PSNR 和 Val PSNR。\n",
    "3. 測試與展示：對 Set5 和 Set14 測試集進行測試，並展示其 Test PSNR。\n",
    "4. 影像放大功能：編寫程式對已訓練完成的模型，輸入一張影像並進行放大處理，並與 Bicubic 結果進行對比。\n",
    "\n",
    "<HR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、讀入 pre-trained 的 pth 檔，再進行 2 次 training，並展示其 Train PSNR 與 Val PSNR 值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\Howard\\AppData\\Local\\Temp\\ipykernel_29908\\2704681886.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  dirThis = 'D:\\python_venv\\SRCNN' # 檔案目錄\n"
     ]
    }
   ],
   "source": [
    "dirThis = 'D:\\python_venv\\SRCNN' # 檔案目錄\n",
    "\n",
    "import sys # 添加路徑\n",
    "sys.path.append(dirThis + 'src/')\n",
    "import os # 創資料夾\n",
    "import time # 計時\n",
    "import SRCNN_srcnn_4 as srcnn # 我們的模型py檔\n",
    "import numpy as np # 使用ndarray及相關計算\n",
    "import pandas as pd # 讀資料\n",
    "from PIL import Image # 處理圖片\n",
    "from tqdm import tqdm # 進度條\n",
    "import matplotlib.pyplot as plt # 畫圖\n",
    "from skimage.color import rgb2ycbcr, ycbcr2rgb # YCbCr操作\n",
    "# from datasets import get_datasets, get_dataloaders # 抓取資料集\n",
    "# from utils import (\n",
    "#     psnr, save_model, save_model_state, \n",
    "#     save_plot, save_validation_results\n",
    "# ) # 訓練相關\n",
    "\n",
    "# torch系列\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# 初始化模型、損失函數和優化器\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msrcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     63\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m     64\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage import io, transform\n",
    "import glob\n",
    "import sys # 添加路徑\n",
    "sys.path.append(dirThis + 'input/Set5')\n",
    "\n",
    "# 定義數據集\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, scale_factor):\n",
    "        self.image_files = glob.glob(os.path.join(image_dir, '*.png'))\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = io.imread(self.image_files[idx], as_gray=True)\n",
    "        img_lr = transform.rescale(img, 1.0 / self.scale_factor, anti_aliasing=True, multichannel=False)\n",
    "        img_lr = transform.rescale(img_lr, self.scale_factor, anti_aliasing=False, multichannel=False)\n",
    "        img = torch.from_numpy(img).float().unsqueeze(0)\n",
    "        img_lr = torch.from_numpy(img_lr).float().unsqueeze(0)\n",
    "        return img_lr, img\n",
    "\n",
    "# 訓練函數\n",
    "def train(model, criterion, optimizer, train_loader, val_loader, num_epochs=2):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_psnr = 0\n",
    "        for data in train_loader:\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_psnr += psnr(targets.cpu().numpy(), outputs.cpu().detach().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_psnr = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_psnr += psnr(targets.cpu().numpy(), outputs.cpu().detach().numpy())\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader)}, Train PSNR: {train_psnr/len(train_loader)}, Val PSNR: {val_psnr/len(val_loader)}')\n",
    "\n",
    "# 設定裝置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 初始化模型、損失函數和優化器\n",
    "model = srcnn().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 加載數據集\n",
    "train_dataset = CustomDataset('train_images', scale_factor=3)\n",
    "val_dataset = CustomDataset('val_images', scale_factor=3)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# 訓練模型並保存預訓練權重\n",
    "train(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)\n",
    "torch.save(model.state_dict(), 'srcnn_pretrained.pth')\n",
    "\n",
    "# 加載預訓練模型並進行額外訓練\n",
    "model.load_state_dict(torch.load('srcnn_pretrained.pth'))\n",
    "train(model, criterion, optimizer, train_loader, val_loader, num_epochs=2)\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'srcnn_finetuned.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_evnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
